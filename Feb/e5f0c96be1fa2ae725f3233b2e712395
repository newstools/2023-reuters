AMSTERDAM, Feb 15 (Reuters) - Ukraine's effective use of artificial intelligence (AI) to target Russian forces has pushed the technology onto the agenda of military and political leaders around the world, the CEO of U.S. software firm Palantir (PLTR.N) said on Wednesday. Speaking at the first international summit on responsible military use of AI, CEO Alex Karp said use of AI in war has moved from a "highly erudite ethics discussion" to a top concern since the start of the conflict in Ukraine. "This has now shifted to: your ability to identify the right technology and implement it will determine what happens on the battlefield," he said. "One of the major things we need to do in the West, is realise this lesson is completely understood by China and Russia." Karp has previously said that Planatir is "responsible for most of the targeting in Ukraine", with the company citing the examples of tanks and artillery. It has marketed its software as a way to quickly determine resources to deploy, taking in feeds from satellites and social media to visualise an army's positions. The U.S. and China are among 50 countries attending the REAIM summit in The Hague this week but the Netherlands and co-host South Korea did not invite Russia. Most delegations are expected to endorse a statement of principles when the conference ends on Thursday, though international rules or a treaty to limit the use of AI in war is seen as far off. Karp said one principle he supports for corporations like his is that they must be able to explain and verify how their technology has been used. He gave the example of an AI-assisted decision to strike enemy soldiers close to a school or hospital. "You need an architecture that allows transparency on the data sources, which data sources were used, what were the (input) feeds and what will allow you to then take it apart." He said that "should be mandated by law. More importantly, it should be mandated by purchasing regulation." Our Standards: The Thomson Reuters Trust Principles.